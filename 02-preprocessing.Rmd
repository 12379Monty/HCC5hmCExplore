# Preprocessing {#preproc}


## Load the data

<!-- THIS ENSURES NO EVALUATION TAKES PLACE BY DEFAULT -->
<!-- TO TURN ON, SET eval=T                            -->
```{r chunk-options, include=FALSE, eval=F}
library("knitr")
opts_chunk$set(eval = FALSE)
```

<!-- Add base libraries -->
```{r libraries, include=FALSE, eval=T}
library("magrittr")
```


The data that are available from NCBI GEO
[Series GSE112679](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE112679)
can be conveniently accessed through an R data package.
Attaching the GSE112679 package makes the count data tables 
available as well as a gene annotation table and a sample description table.
See [GSE112679 R Data Package page](https://12379monty.github.io/GSE112679/).
For the Cai et al. [@Cai:2019aa] model fitting and analysis, samples were separated into
`Train` and `Val-1` subsets.  `Val-2` was an external validation set.

```{r loadData, cache=F}

if (!("GSE112679" %in% rownames(installed.packages()))) {
  if (!requireNamespace("devtools", quietly = TRUE)) {
    install.packages("devtools")
  }
  devtools::install_github("12379Monty/GSE112679")
}
library(GSE112679)

with(
  sampDesc %>% dplyr::filter(sampType == "blood"),
  table(outcome, trainValGroup, exclude = NULL)
)

```

For this analysis, we will consider early stage cancer samples
and healthy or benign samples from the `Train` or `Val-1` subsets.

```{r subsetSamples, cache=T, cache.vars=c('sampDescA','groupCol')}

sampDescA <-
  sampDesc %>%
  dplyr::filter(sampType == "blood" & (trainValGroup %in% c("Train", "Val-1")) &
    ((outcome2 == "BenignHealthy") | (outcome2 == "HCC" & stage == "Early"))) %>%
  dplyr::rename(group = outcome2) %>%
  dplyr::arrange(group, sampID)

# Recode group
sampDescA$group <- with(sampDescA, ifelse(group == "BenignHealthy", "Control", group))

# set groupCol for later
groupCol <- c("#F3C300", "#875692")
names(groupCol) <- unique(sampDescA$group)

with(sampDescA, table(group, exclude = NULL))

```


The features are counts of reads captured by chemical labeling, and indicate
the level of 5-hydroxymethylcytosines within each gene body.  Cai et al. (2019),
Li et al. (2017) and Song et al. (2017) [@Cai:2019aa;@Li:2017aa;@Song:2017aa]
all analyze 5hmC gene body counts using standard RNA-Seq methodologies, and we will
do the same here.  

Note that before conducting any substantive analyses, the data would normally
be very carefully examined for any sign of quality variation between groups
of samples.  This analysis would integrate sample meta data - where and when were
the blood samples collected - as well as library preparation and sequencing metrics
in order to detect any sign of processing artifacts that may be present in the dataset.
This is particularly important when dealing with blood samples as variable
DNA quality degradation is a well known challenge that is encountered when dealing with
such samples [@Huang:2017aa].  Although blood specimen handling protocols can be 
put in place to minimize quality variation [@Permenter:2015aa], variability
can never be completely eradicated, especially in the context of blood samples
collected by different groups, working in different environments.  The problem
of variable DNA quality becomes paricularly pernicuous when it is compounded
with a confounding factor that sneaks in when the control sample collection
events are separated in time and space from the cancer sample collection events;
an all too common occurence.  

As proper data QC requires an intimate familiarity with the details of
data collection and processing, such a task cannot be untertaken here.
We will simply run a *minimal set of QC sanity checks* to make sure that
there are no apparent systematic effects in the data.


```{r getfeatures, cache=T, cache.vars=c('featureCountsA')}

 # Note that unique sample identifier are stored 
 # in the rownames of the sample description table 
 # and in the column names of the feature count tables.

  featureCountsA <- cbind(Train_featureCount, 
                          Val1_featureCount, 
                          Val2_featureCount)[,rownames(sampDescA)]

```

Look at coverage - make sure there isn't too much disparity of coverage 
across samples. 

```{r coverage, cache=T, fig.height=4, fig.width=10, fig.cap='Sample log2 count boxplots'}

par(mar = c(1, 3, 2, 1))
boxplot(log2(featureCountsA + 1),
  ylim = c(3, 11),
  staplewex = 0,       # remove horizontal whisker lines
  staplecol = "white", # just to be totally sure :)
  outline = F,         # remove outlying points
  whisklty = 0,        # remove vertical whisker lines
  las = 2, horizontal = F, xaxt = "n",
  border = groupCol[sampDescA$group]
)
legend("top", legend = names(groupCol), text.col = groupCol, ncol = 2, bty = "n")

# Add reference lines
SampleMedian <- apply(log2(featureCountsA + 1), 2, median)
abline(h = median(SampleMedian), col = "grey")
axis(side = 2, at = round(median(SampleMedian), 1), las = 2, col = "grey", line = -1, tick = F)

```


Look at relative log representation (RLR) (in the context of measuring the density of 
5hmC marks in genes, we refer to `representation` as opposed to `expression`) -
make sure the shapes of the distributions are not widely different.

```{r rlr, cache=T, cache.vars='lcpm_mtx', fig.height=4, fig.width=10, fig.cap='Sample RLR', eval=T, echo=T}

lcpm_mtx <- edgeR::cpm(featureCountsA, log = T)
median_vec <- apply(lcpm_mtx, 1, median)
RLR_mtx <- sweep(lcpm_mtx, 1, median_vec, "-")

par(mar = c(1, 3, 2, 1))
boxplot(RLR_mtx,
  xlab = "", ylim = c(-.6, .6),
  staplewex = 0, # remove horizontal whisker lines
  staplecol = "white", # just to be totally sure :)
  outline = F, # remove outlying points
  whisklty = 0, # remove vertical whisker lines
  las = 2, horizontal = F, xaxt = "n",
  border = groupCol[sampDescA$group]
)
legend("top", legend = names(groupCol), text.col = groupCol, ncol = 2, bty = "n")

# Add group Q1, Q3
for (GRP in unique(sampDescA$group)) {
  group_ndx <- which(sampDescA$group == GRP)
  group_Q1Q3_mtx <- apply(RLR_mtx[, group_ndx], 2, quantile, prob = c(.25, .75))
  abline(h = apply(group_Q1Q3_mtx, 1, median), col = groupCol[GRP], lwd = 2)
}


```

We note that the HCC samples have slightly more variable coverage distribution.
A few samples are quite different.


## Normalize - $log_2$ CPM

We will use $log_2$ normalized counts per million as our indicator
of 5hmC gene representation in our downstream analyses.
We will first remove weakly represented genes, as is typically done when
analyzing RNA-Seq data [@Law:2018aa].   Before removing genes, let's examine the
shapes of the distributions.  

```{r densityLcpm, fig.height=4, fig.width=10, fig.cap='Sample $log_2$ CPM densities', eval=T, echo=T}

par(mar = c(1, 3, 2, 1))
plot(density(lcpm_mtx[, 1]),
  col = groupCol[sampDescA$group[1]],
  lwd = 2, ylim = c(0, .25), las = 2, main = "", xlab = ""
)
abline(v = 0, col = 3)
# After verifying that there are no outliers can plot a random subset 
for (JJ in sample(2:ncol(lcpm_mtx), size = 100)) {
  den <- density(lcpm_mtx[, JJ])
  lines(den$x, den$y, col = groupCol[sampDescA$group[JJ]], lwd = 2)
} # for(JJ

legend("topright", legend = names(groupCol), text.col = groupCol, bty = "n")

```

We notice many weakly represented genes as is the case with RNA-Seq data.
Law et al. (2018) [@Law:2018aa] point out that genes that are not expressed at a biologically 
meaningful level in any condition should be discarded to reduce the 
subset of genes to those that are of interest, and to reduce the number of tests 
carried out downstream when looking at differential expression.  

<!--
This multiple testing problem may be less of a problem when the primary interest is in
building a classifier, but carrying weakly expressed (or represented, in this case)
is still a problem as it makes removing the association between expression level
and variability difficult.
-->


`r  LibSizeSum <- summary( colSums(featureCountsA) / 1e6 )`
`r CPM_THR <- 10; SAMP_THR <- 10` 

Using a nominal CPM value of `r CPM_THR`,  genes are deeemed to be `represented` 
if their expression is above this threshold, and not represented otherwise. 
Genes must be `represented` in at least `r SAMP_THR` samples across the entire 
dataset to be retained for downstream analysis. Here, a CPM value of `r CPM_THR` 
means that a gene is represented if it has at least `r round(CPM_THR*LibSizeSum['Min.'])`
reads in the sample with the lowest sequencing depth 
(library size `r round(LibSizeSum['Min.'],1)` million).  Note that the thresholds
used here are arbitrary as there are no hard and fast rules to set thes by.

<!-- or at least 
`r round(CPM_THR*LibSizeSum['Max.'])` counts in the sample with the 
greatest sequencing depth (library size `r round(LibSizeSum['Max.'],1)` million).
-->

Remove weakly represented genes.

```{r removeWeak, cache=T, cache.vars=c('featureCountsA', 'genes_annotA', 'lcpm_mtx')}

weak_flg <- rowSums(edgeR::cpm(featureCountsA) > CPM_THR) < SAMP_THR

cat("Removing", paste0(round(100 * mean(weak_flg), 1), "%"), "of genes...\n")
featureCountsA <- featureCountsA[!weak_flg, ]
genes_annotA <- genes_annot[rownames(featureCountsA), ]
lcpm_mtx <- edgeR::cpm(featureCountsA, log = T)

dim(lcpm_mtx)

```

Replot densities.


```{r densityLcpm2, fig.height=4, fig.width=10, fig.cap='Sample $log_2$ CPM densities after removing weak genes', eval=T, echo=T}

par(mar = c(1, 3, 2, 1))
plot(density(lcpm_mtx[, 1]),
  col = groupCol[sampDescA$group[1]],
  lwd = 2, ylim = c(0, .25), las = 2, main = "", xlab = ""
)
abline(v = 0, col = 3)
# After verifying that there are no outliers can plot random subset
for (JJ in sample(2:ncol(lcpm_mtx), size = 100)) {
  den <- density(lcpm_mtx[, JJ])
  lines(den$x, den$y, col = groupCol[sampDescA$group[JJ]], lwd = 2)
} # for(JJ

legend("topright", legend = names(groupCol), text.col = groupCol, bty = "n")

```

As another sanity check, we will look at a 
multidimensional scaling plot of distances between gene expression
profiles.  We use `plotMDS` in limma package [@Ritchie:2015aa]),
which plots samples on a two-dimensional scatterplot so that distances on
the plot approximate the typical log2 fold changes between the
samples.   

```{r plotMDS, cache=T, fig.height=5, fig.width=10, fig.cap='MDS plots of log-CPM values'}

 par(mfcol=c(1,2), mar=c(4,4,2,1), xpd=NA, oma=c(0,0,2,0))

# without loss of generality or sensitivity, sample 300 samples
# this is simply a matter of convenience and to save computing time
 set.seed(1)
 samp_ndx <- sample(1:ncol(lcpm_mtx), size=500)

 
 # Dim 1, 2
 MDS.out <- limma::plotMDS(lcpm_mtx[,samp_ndx], col=groupCol[sampDescA$group[samp_ndx]], pch=1)

 legend("topright", legend = names(groupCol), text.col = groupCol, bty = "n")


 # Dim 3, 4
 MDS.out <- limma::plotMDS(lcpm_mtx[,samp_ndx], col=groupCol[sampDescA$group[samp_ndx]], pch=1,
     dim.plot=3:4)

```

The MDS plot, which is analogous to a PCA plot adapted to gene exression data,
does not indicate strong clustering of samples.  The fanning pattern observed in the
first two dimensions indicates that a few samples are drifting way from the
core set, but in no particular direction.  

## Analysis of coverage variability

We will use the methods described in Hart et al. (2013) [@Hart:2013aa] 
to characterize coverage variability in these data. 
These methods do not take multiple comparisons into account. 
Other tools for sample size calculation in RNA-Seq studies include 
Bi and Liu (2016) [@Bi:2016aa,] 
Baccarella (2018) [@Baccarella:2018aa], 
Guo (2014) [@Guo:2014aa], 
Yu (2017) [@Yu:2017aa], 
Zhao (2018) [@Zhao:2018ab]. 
Poplawski (2018) [@Poplawski:2017aa] 
evaluated RNA-seq sample size tools identified from a systematic search. They found the six evaluated tools provided widely different answers, which were strongly affected by fold change.


The references listed above aim at providing guidance for RNA-Seq experimental design.
There is much discussion and a wide range of opinion on sample size requirements
for producing reproducible RNA-Seq results.  At one end of the spectrum, 
Ein-Dor et al. (2006) [@Ein-Dor:2006aa] argue that thousands of samples are needed to 
generate a robust gene list for predicting outcome in cancer.  At the other end,
Dobbin et al. (2007, 2008) [@Dobbin:2007aa;@Dobbin:2008aa] claim that sample sizes in 
the range of 20–30 per class may be adequate for building a good predictor in many cases. 
Part of the disparity in sample size requirement recomendation comes from 
differences of opinion in terms of what constitutes `reproducible results`. 
In the context of sample classification, if we focus on  the predicted probabilities
for individual samples, we may find good  reproducibility across studies with
moderate samples sizes.  If on the other hand, we closely inspect the gene
signatures reported across studies, much greater samples sizes migth be required to
achieve concordance.  Kim (2009) [@Kim:2009aa], like Ein-Dor et al., also find
issues in RNA-Seq research in terms of the instability of identified prognostic 
gene signatures, few overlap between independently developed prognostic gene signatures, and
poor inter-study applicability of gene signatures.  Fan et al. (2006) [@Fan:2006aa],
om the other hand, found good concordance among gene-expression–based predictors 
for breast cancer.  We will return to this question when we examine
the relationship between classification model results and sample size in this
dataset later on this paper.  


For two groups comparisons, the basic formula for the required number of samples per group is:

$$ n = 2(z_{1-\alpha/2} + z_{\beta})^2 \frac{(1/\mu + \sigma^2)}{ln(\Delta^2)} $$

* The parameters $\alpha$ and $\beta$ are size and power of the test.  
* z the corresponding cut points.  
* $\Delta$ is the testing target or effect size.   

These three parameters will be fixed across genes or a given study, and are often dictated by
external requirements. Typical values might be $\Delta = 1.5$ (a.k.a fold change),
corresponding to detection of a 50% change in gene expression between the two groups.
$z_{1 - .05/2} = 1.96$, corresponding to a two sided test at $\alpha = 0.05$;
and $z_{.90}= 1.28$ corresponding to 90% power.
The other two variables will be gene and experiment dependent: the depth of coverage $\mu$ of the gene,
and the coefficient of variation $\sigma$ in this gene between biological replicates.
The technical variation of the comparison is inversely proportional to the number of sequenced reads
for the gene and therefore decreases with sequencing depth.
The biological variation is a property of the particular gene/model system/condition under study.
One would expect it to be smaller for uniform systems such as cell culture and/or products that
are under tight regulatory control, and larger for less uniform replicates such as human subject samples.

<br/>
<br/>

Before examining biological variability lets take a look at
the sequencing rates.



```{r sumCount, cache=T, cache.vars='DD.cpmSum.frm'}

countSum_frm <- do.call(
  "rbind",
  lapply(unique(sampDescA$group), function(GRP) {
    GRP_featureCountsA <- featureCountsA[, sampDescA$group == GRP]
    N_GRP <- ncol(GRP_featureCountsA)
    MeanTotCovM <- mean(colSums(featureCountsA[, sampDescA$group == GRP])) / 1e6

    GRP_countSum_mtx <- do.call("cbind", lapply(
      1:ncol(GRP_featureCountsA),
      function(CC) {
        CC_cpm_vec <- GRP_featureCountsA[, CC]
        100 * table(cut(CC_cpm_vec, breaks = c(0, .1, 1, 10, 50, 100, 1000, Inf))) / 
                  length(CC_cpm_vec)
      }
    ))

    GRP_countSum_vec <- apply(GRP_countSum_mtx, 1, median)

    GRP_Zeros_vec <- colSums(GRP_featureCountsA == 0)
    GRP_ZerosPct_vec <- 100 * GRP_Zeros_vec / nrow(GRP_featureCountsA)

    data.frame(
      Group = GRP, N = N_GRP, MeanTotCovM = round(MeanTotCovM, 1),
      Zeros = median(GRP_Zeros_vec), ZeroPct = median(GRP_ZerosPct_vec),
      t(GRP_countSum_vec), check.names = F
    )
  })
)


knitr::kable(countSum_frm)

```



As in Hart et al. (2013) [@Hart:2013aa]
<!--for each gene with average counts of at least 5-->, we estimate the 
biological coefficient of variation (CV) in expression across samples in the data set
using a negative binomial model (edgeR).  
From [edgeR User's Guide](https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf)
, the biolgical coefficient of variation (BCV), is the square root of the dispersion
parameter under the negative binomial model. Hence, it is equivalent to estimating the
dispersion(s) of the negative binomial model.

```{r estBCV, cache=T, cache.vars=c('BCV_mtx','BCV_90perc_vec', 'BCV_50perc_vec'), fig.height=5, fig.width=10, fig.cap="Cumulative Distribution of CV - rug = 90th percentile"}

 #suppressMessages(reqduire(spatstat))

 BCV_mtx <- do.call('cbind', lapply(unique(sampDescA$group), 
 function(GRP) {
  GRP_dgel <- edgeR::DGEList(counts=featureCountsA[, sampDescA$group==GRP])
  GRP_dgel <- edgeR::estimateDisp(GRP_dgel)

  sqrt(GRP_dgel$tagwise.dispersion)
  }))

 colnames(BCV_mtx) <- unique(sampDescA$group)


 # Plot
 plot(spatstat::CDF(density(BCV_mtx[,1])), 
      col=groupCol[colnames(BCV_mtx)[1]], lwd=2, ylab='Prob(BCV<x)',
   xlim=c(0, 0.5))
 for(JJ in 2:ncol(BCV_mtx))
 plot(spatstat::CDF(density(BCV_mtx[,JJ])), 
      col=groupCol[colnames(BCV_mtx)[JJ]], lwd=2, add=T, xlim=c(0, 2.0))

 legend('bottomright', legend=names(groupCol), col=groupCol, lwd=2)
  
 BCV_90perc_vec <- apply(BCV_mtx,2,quantile, prob=0.90)
 BCV_50perc_vec <- apply(BCV_mtx,2,quantile, prob=0.50)
 for(JJ in 1:length(BCV_90perc_vec)) 
 rug(BCV_90perc_vec[JJ], lwd=2, col=groupCol[names(BCV_90perc_vec)[JJ]])


```

<br/>

<!-- 
 SampleSize_f <- function(Alpha=.01, Beta=.80, Delta=2, Mu, Disp)
 {temp <- qnorm(1-Alpha/2) + qnorm(Beta)
  vtemp <- 1/Mu + Disp
  2*vtemp*(temp/log(Delta))^2}

 cat("SampleSize_f(Mu=10, Disp=.4^2):\n")
 SampleSize_f(Mu=10, Disp=.4^2)
-->

We can now look at sample size estimates to detect 
various effect sizes.

```{r sampleSizeCurve, cache=T, cache.vars='', fig.height=8, fig.width=11,fig.cap='Sample Size Estimates'}

par(mfrow = c(2, 1), mar = c(3, 3, 2, 1), oma = c(2, 2, 2, 0))

for (EFFECT in c(1.25, 1.10)) {
  cat("rnapower(depth=10, cv=.4, effect=", EFFECT, "alpha=.01, power=.80):\n")
  RNASeqPower::rnapower(depth = 10, cv = .4, effect = EFFECT, alpha = .01, power = .80)


  plot(
    x = 1:50, y = RNASeqPower::rnapower(depth = 1:50, cv = 1.2, 
                  effect = EFFECT, alpha = .05, power = .80),
    type = "n", lwd = 2, ylim = c(0, ifelse(EFFECT == 2, 50, 250)), ylab = "", xlab = ""
  )

  for (GRP in names(BCV_90perc_vec)) {
    lines(
      x = 1:50, y = RNASeqPower::rnapower(depth = 1:50, cv = BCV_90perc_vec[GRP], 
                    effect = EFFECT, alpha = .05, power = .80),
      lwd = 2, col = groupCol[GRP]
    )
  }

  title(paste("Effect =", EFFECT, "Alpha=0.05, Beta=0.80"))
}

legend("topright",
  legend = paste(names(BCV_90perc_vec), "CV =", round(BCV_90perc_vec, 2)),
  col = groupCol[names(BCV_90perc_vec)], lwd = 2
)

mtext(side = 1, outer = T, "Gene Coverage")
mtext(side = 2, outer = T, "Samples Needed")
mtext(side = 3, outer = T, cex = 1.25, "Negative Binomial 2 Group Sample Size Curves")

abline(h = 5, col = "grey")
```

## Differential representation analysis

   - word on GC content



