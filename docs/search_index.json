[
["index.html", "DNA Hydroxymethylation in Hepatocellular Carcinoma Preamble License", " DNA Hydroxymethylation in Hepatocellular Carcinoma Francois Collin 2020-08-29 Preamble This vignette offers some exploratory data analyses of data available from the NCBI GEO web site. License This work by Francois Collin is licensed under a Creative Commons Attribution 4.0 International License "],
["intro.html", "Section 1 Introduction", " Section 1 Introduction The goal of detecting cancer at the earliest stage of development with a non-invasive procedure has busied many groups with the task of perfecting techniques to support what has become commonly known as a liquid biopsy - the analysis of biomarkers circulating in fluids such as blood, saliva or urine. Epigenetic biomarkers present themselves as good candidates for this application (Gai and Sun (2019) [1]). In particular, given their prevalence in the human genome, close correlation with gene expression and high chemical stability, DNA modifications such as 5-methylcytosine (5mC) and 5-hydroxymethylcytosine (5hmC) are DNA epigenetic marks that provide much promise as cancer diagnosis biomarkers that could be profitably analyzed in liquid biopsies [2–5]. Li et al. (2017) [3] used a sensitive and selective chemical labeling technology to extract genome-wide 5hmC profiles from circulating cell-free DNA (cfDNA) as well as from genomic DNA (gDNA) collected from a cohort of 260 patients recently diagnosed with colorectal, gastric, pancreatic, liver or thyroid cancer and normal tissues from 90 healthy individuals They found 5hmC-based biomarkers of circulating cfDNA to be highly predictive of some cancer types. Similar small sample size findings were reported in Song et al. (2017) [4]. Focusing on hepatocellular carcinoma, Cai et al. (2019) [2] assembled a sizable dataset to demonstrate the feasibility of using features derived from 5-hydroxymethylcytosines marks in circulating cell-free DNA as a non-invasive approach for the early detection of hepatocellular carcinoma. The data that are the basis of that report are available on the NCBI GEO web site (Series GSE112679). The data have also been bundled in a R data package which can be installed from github: if (!requireNamespace(&quot;devtools&quot;, quietly = TRUE)) install.packages(&quot;devtools&quot;) devtools::install_github(&quot;12379Monty/GSE112679&quot;) An important question in the early development of classifiers of the sorts that are the basis of any liquid biopsy diagnostic tool is how many samples should be collected to make properly informed decisions. In this report we will explore the GSE112679 data to shed some light on the relationship between sample size and model performance in the context classifying samples based on 5hmC data. In Section 2 we preprocess the data that we will use for the classification analysis and perform some light QC analyses. In Section 3 we fit some models to discriminate between early stage HCC and control samples and examine their performance. In Section 4 we examine the results of fitting a suite of models to investigate the effect of sample size on model performance. "],
["preproc.html", "Section 2 Preprocessing 2.1 Load the data 2.2 Normalized representation feature - \\(log_2\\) CPM 2.3 Analysis of coverage variability 2.4 Differential representation analysis", " Section 2 Preprocessing 2.1 Load the data The data that are available from NCBI GEO Series GSE112679 can be conveniently accessed through an R data package. Attaching the GSE112679 package makes the count data tables available as well as a gene annotation table and a sample description table. See GSE112679 R Data Package page. For the Cai et al. [2] model fitting and analysis, samples were separated into Train and Val-1 subsets. Val-2 was an external validation set. if (!(&quot;GSE112679&quot; %in% rownames(installed.packages()))) { if (!requireNamespace(&quot;devtools&quot;, quietly = TRUE)) { install.packages(&quot;devtools&quot;) } devtools::install_github(&quot;12379Monty/GSE112679&quot;) } library(GSE112679) with( sampDesc %&gt;% dplyr::filter(sampType == &quot;blood&quot;), table(outcome, trainValGroup, exclude = NULL) ) ## trainValGroup ## outcome Train Val-1 Val-2 ## Benign 253 132 3 ## CHB 190 96 0 ## Cirrhosis 73 33 0 ## HCC 335 809 60 ## Healthy 269 124 177 For this analysis, we will consider early stage cancer samples and healthy or benign samples from the Train or Val-1 subsets. sampDescA &lt;- sampDesc %&gt;% dplyr::filter(sampType == &quot;blood&quot; &amp; (trainValGroup %in% c(&quot;Train&quot;, &quot;Val-1&quot;)) &amp; ((outcome2 == &quot;BenignHealthy&quot;) | (outcome2 == &quot;HCC&quot; &amp; stage == &quot;Early&quot;))) %&gt;% dplyr::rename(group = outcome2) %&gt;% dplyr::arrange(group, sampID) # Recode group sampDescA$group &lt;- with(sampDescA, ifelse(group == &quot;BenignHealthy&quot;, &quot;Control&quot;, group)) # set groupCol for later groupCol &lt;- c(&quot;#F3C300&quot;, &quot;#875692&quot;) names(groupCol) &lt;- unique(sampDescA$group) with(sampDescA, table(group, exclude = NULL)) ## group ## Control HCC ## 778 555 The features are counts of reads captured by chemical labeling, and indicate the level of 5-hydroxymethylcytosines within each gene body. Cai et al. (2019), Li et al. (2017) and Song et al. (2017) [2–4] all analyze 5hmC gene body counts using standard RNA-Seq methodologies, and we will do the same here. Note that before conducting any substantive analyses, the data would normally be very carefully examined for any sign of quality variation between groups of samples. This analysis would integrate sample meta data - where and when were the blood samples collected - as well as library preparation and sequencing metrics in order to detect any sign of processing artifacts that may be present in the dataset. This is particularly important when dealing with blood samples as variable DNA quality degradation is a well known challenge that is encountered when dealing with such samples [6]. Although blood specimen handling protocols can be put in place to minimize quality variation [7], variability can never be completely eradicated, especially in the context of blood samples collected by different groups, working in different environments. The problem of variable DNA quality becomes paricularly pernicuous when it is compounded with a confounding factor that sneaks in when the control sample collection events are separated in time and space from the cancer sample collection events; an all too common occurence. As proper data QC requires an intimate familiarity with the details of data collection and processing, such a task cannot be untertaken here. We will simply run a minimal set of QC sanity checks to make sure that there are no apparent systematic effects in the data. # Note that unique sample identifier are stored # in the rownames of the sample description table # and in the column names of the feature count tables. featureCountsA &lt;- cbind(Train_featureCount, Val1_featureCount, Val2_featureCount)[,rownames(sampDescA)] We first look at coverage - make sure there isn’t too much disparity of coverage across samples. To detect shared variability, samples can be annotated and ordered according to sample features that may be linked to sample batch processing. Here we the samples have been ordered by group and sample id (an alias of geoAcc). par(mar = c(1, 3, 2, 1)) boxplot(log2(featureCountsA + 1), ylim = c(3, 11), staplewex = 0, # remove horizontal whisker lines staplecol = &quot;white&quot;, # just to be totally sure :) outline = F, # remove outlying points whisklty = 0, # remove vertical whisker lines las = 2, horizontal = F, xaxt = &quot;n&quot;, border = groupCol[sampDescA$group] ) legend(&quot;top&quot;, legend = names(groupCol), text.col = groupCol, ncol = 2, bty = &quot;n&quot;) # Add reference lines SampleMedian &lt;- apply(log2(featureCountsA + 1), 2, median) abline(h = median(SampleMedian), col = &quot;grey&quot;) axis(side = 2, at = round(median(SampleMedian), 1), las = 2, col = &quot;grey&quot;, line = -1, tick = F) Figure 2.1: Sample log2 count boxplots We nest look at relative log representation (RLR) (in the context of measuring the density of 5hmC marks in genes, we refer to representation as opposed to expression; the two can be used interchangibly) - make sure the shapes of the distributions are not widely different. lcpm_mtx &lt;- edgeR::cpm(featureCountsA, log = T) median_vec &lt;- apply(lcpm_mtx, 1, median) RLR_mtx &lt;- sweep(lcpm_mtx, 1, median_vec, &quot;-&quot;) par(mar = c(1, 3, 2, 1)) boxplot(RLR_mtx, xlab = &quot;&quot;, ylim = c(-.6, .6), staplewex = 0, # remove horizontal whisker lines staplecol = &quot;white&quot;, # just to be totally sure :) outline = F, # remove outlying points whisklty = 0, # remove vertical whisker lines las = 2, horizontal = F, xaxt = &quot;n&quot;, border = groupCol[sampDescA$group] ) legend(&quot;top&quot;, legend = names(groupCol), text.col = groupCol, ncol = 2, bty = &quot;n&quot;) # Add group Q1, Q3 for (GRP in unique(sampDescA$group)) { group_ndx &lt;- which(sampDescA$group == GRP) group_Q1Q3_mtx &lt;- apply(RLR_mtx[, group_ndx], 2, quantile, prob = c(.25, .75)) abline(h = apply(group_Q1Q3_mtx, 1, median), col = groupCol[GRP], lwd = 2) } Figure 2.2: Sample RLR We note that the HCC samples have slightly more variable coverage distribution. A few samples are quite different. 2.2 Normalized representation feature - \\(log_2\\) CPM We will use \\(log_2\\) normalized counts per million as our indicator of 5hmC gene representation in our downstream analyses. We will first remove weakly represented genes, as is typically done when analyzing RNA-Seq data [8]. Before removing genes, let’s examine the shapes of the distributions. par(mar = c(3, 3, 2, 1)) plot(density(lcpm_mtx[, 1]), col = groupCol[sampDescA$group[1]], lwd = 2, ylim = c(0, .25), las = 2, main = &quot;&quot;, xlab = &quot;&quot; ) abline(v = 0, col = 3) # After verifying no outliers, can plot a random subset for (JJ in sample(2:ncol(lcpm_mtx), size = 100)) { den &lt;- density(lcpm_mtx[, JJ]) lines(den$x, den$y, col = groupCol[sampDescA$group[JJ]], lwd = 2) } # for(JJ legend(&quot;topright&quot;, legend = names(groupCol), text.col = groupCol, bty = &quot;n&quot;) Figure 2.3: Sample \\(log_2\\) CPM densities We notice many weakly represented genes as is the case with RNA-Seq data. Law et al. (2018) [8] point out that genes that are not expressed at a biologically meaningful level in any condition should be discarded to reduce the subset of genes to those that are of interest, and to reduce the number of tests carried out downstream when looking at differential expression. Using a nominal CPM value of 10, genes are deeemed to be represented if their expression is above this threshold, and not represented otherwise. Genes must be represented in at least 10 samples across the entire dataset to be retained for downstream analysis. Here, a CPM value of 10 means that a gene is represented if it has at least 29 reads in the sample with the lowest sequencing depth (library size 2.9 million). Note that the thresholds used here are arbitrary as there are no hard and fast rules to set thes by. Remove weakly represented genes. Removing 28.1% of genes… featureCountsA &lt;- featureCountsA[!weak_flg, ] genes_annotA &lt;- genes_annot[rownames(featureCountsA), ] lcpm_mtx &lt;- edgeR::cpm(featureCountsA, log = T) dim(lcpm_mtx) ## [1] 13725 1333 Replot densities after removing weak genes. par(mar = c(3, 3, 2, 1)) plot(density(lcpm_mtx[, 1]), col = groupCol[sampDescA$group[1]], lwd = 2, ylim = c(0, .25), las = 2, main = &quot;&quot;, xlab = &quot;&quot; ) abline(v = 0, col = 3) # After verifying no outliers, can plot a random subset for (JJ in sample(2:ncol(lcpm_mtx), size = 100)) { den &lt;- density(lcpm_mtx[, JJ]) lines(den$x, den$y, col = groupCol[sampDescA$group[JJ]], lwd = 2) } # for(JJ legend(&quot;topright&quot;, legend = names(groupCol), text.col = groupCol, bty = &quot;n&quot;) Figure 2.4: Sample \\(log_2\\) CPM densities after removing weak genes Note that the \\(log_2(CMP)\\) distribution is not quite symmetric. As another sanity check, we will look at a multidimensional scaling plot of distances between gene expression profiles. We use plotMDS in limma package [9]), which plots samples on a two-dimensional scatterplot so that distances on the plot approximate the typical log2 fold changes between the samples. par(mfcol=c(1,2), mar=c(4,4,2,1), xpd=NA, oma=c(0,0,2,0)) # without loss of generality or sensitivity, sample 300 samples # this is simply a matter of convenience and to save time set.seed(1) samp_ndx &lt;- sample(1:ncol(lcpm_mtx), size=500) MDS.out &lt;- limma::plotMDS(lcpm_mtx[,samp_ndx], col=groupCol[sampDescA$group[samp_ndx]], pch=1) legend(&quot;topleft&quot;, legend = names(groupCol), text.col = groupCol, bty = &quot;n&quot;) MDS.out &lt;- limma::plotMDS(lcpm_mtx[,samp_ndx], col=groupCol[sampDescA$group[samp_ndx]], pch=1, dim.plot=3:4) Figure 2.5: MDS plots of log-CPM values The MDS plot, which is analogous to a PCA plot adapted to gene exression data, does not indicate strong clustering of samples. The fanning pattern observed in the first two dimensions indicates that a few samples are drifting way from the core set, but in no particular direction. 2.3 Analysis of coverage variability We will use the methods described in Hart et al. (2013) [10] to characterize coverage variability in these data. These methods do not take multiple comparisons into account. Other tools for sample size calculation in RNA-Seq studies include Bi and Liu (2016) [11], Baccarella (2018) [12], Guo (2014) [13], Yu (2017) [14], and Zhao (2018) [15]. Poplawski (2018) [16] evaluated RNA-seq sample size tools identified from a systematic search. They found the six evaluated tools provided widely different answers, which were strongly affected by fold change. The references listed above aim at providing guidance for RNA-Seq experimental design. There is much discussion and a wide range of opinion on sample size requirements to ensure reproducibility in RNA-Seq results. At one end of the spectrum, Ein-Dor et al. (2006) [17] argue that thousands of samples are needed to generate a robust gene list for predicting outcome in cancer. At the other end, Dobbin et al. (2007, 2008) [18,19] claim that sample sizes in the range of 20–30 per class may be adequate for building a good predictor in many cases. Part of the disparity in sample size requirement recomendation comes from differences of opinion in terms of what constitutes reproducible results. In the context of sample classification, if we focus on the predicted probabilities for individual samples, we may find good reproducibility across studies with moderate samples sizes. If, on the other hand, we closely inspect the gene signatures reported across studies, much greater sample sizes may be required to achieve concordance. Kim (2009) [20], like Ein-Dor et al., also find issues in RNA-Seq research in terms of the instability of identified prognostic gene signatures, few overlap between independently developed prognostic gene signatures, and poor inter-study applicability of gene signatures. Fan et al. (2006) [21], on the other hand, found good concordance among gene-expression–based predictors for breast cancer. We will return to this question when we examine the relationship between classification model results and sample size in this dataset later on this paper. For two groups comparisons, the basic formula for the required number of samples per group is: \\[ n = 2(z_{1-\\alpha/2} + z_{\\beta})^2 \\frac{(1/\\mu + \\sigma^2)}{ln(\\Delta^2)} \\] The parameters \\(\\alpha\\) and \\(\\beta\\) are size and power of the test. \\(\\Delta\\) is the targeted effect size. \\(\\mu\\) and \\(\\sigma\\) are the mean and coefficient of variation of the distribution of measurement, gene representation indices in this case. These three parameters will be fixed across genes or a given study, and are often dictated by external requirements. Typical values might be an effect size of \\(\\Delta = 1.5\\) (a.k.a fold change), corresponding to detection of a 50% change in gene expression between the two groups. \\(z_{1 - .05/2} = 1.96\\), corresponding to a two sided test at size \\(\\alpha = 0.05\\); and \\(z_{.90}= 1.28\\) corresponding to 90% power. The other two variables will be gene and experiment dependent: the normalized depth of coverage \\(\\mu\\) of the gene, and the coefficient of variation \\(\\sigma\\) in this gene between biological replicates. The technical variation of the comparison is inversely proportional to the number of sequenced reads for the gene and therefore decreases with sequencing depth. The biological variation is a property of the particular gene/model system/condition under study. One would expect it to be smaller for uniform systems such as cell culture and/or products that are under tight regulatory control, and larger for less uniform replicates such as human subject samples. The dataset under study in this report is the first of its kind to give us an idea of variability levels in 5hmC representation. As in Hart et al. (2013) [10] , we estimate the biological coefficient of variation (CV) in expression across samples in the data set using a negative binomial model. BCV_mtx &lt;- do.call(&#39;cbind&#39;, lapply(unique(sampDescA$group), function(GRP) { GRP_dgel &lt;- edgeR::DGEList(counts=featureCountsA[, sampDescA$group==GRP]) GRP_dgel &lt;- edgeR::estimateDisp(GRP_dgel) sqrt(GRP_dgel$tagwise.dispersion) })) ## Design matrix not provided. Switch to the classic mode. ## Design matrix not provided. Switch to the classic mode. colnames(BCV_mtx) &lt;- unique(sampDescA$group) plot(spatstat::CDF(density(BCV_mtx[,1])), col=groupCol[colnames(BCV_mtx)[1]], lwd=2, ylab=&#39;Prob(BCV&lt;x)&#39;, xlim=c(0, 0.5)) for(JJ in 2:ncol(BCV_mtx)) plot(spatstat::CDF(density(BCV_mtx[,JJ])), col=groupCol[colnames(BCV_mtx)[JJ]], lwd=2, add=T, xlim=c(0, 2.0)) legend(&#39;bottomright&#39;, legend=names(groupCol), col=groupCol, lwd=2) BCV_90perc_vec &lt;- round(apply(BCV_mtx,2,quantile, prob=0.90), 2) BCV_50perc_vec &lt;- round(apply(BCV_mtx,2,quantile, prob=0.50), 2) for(JJ in 1:length(BCV_90perc_vec)) rug(BCV_90perc_vec[JJ], lwd=2, ticksize = 0.05, col=groupCol[names(BCV_90perc_vec)[JJ]]) Figure 2.6: Cumulative Distribution of CV - rug = 90th percentile We can now look at sample size estimates to required to detect various effect sizes. The effect sizes examined here are selected based on the differential representation analysis in Section 2.4 below. par(mfrow = c(2, 1), mar = c(3, 3, 2, 1), oma = c(2, 2, 2, 0)) for (EFFECT in c(1.10, 1.20)) { plot( x = 10:100, y = RNASeqPower::rnapower(depth = 10:100, cv = max(BCV_90perc_vec), effect = EFFECT, alpha = .05, power = .80), lwd = 2, ylab = &quot;&quot;, xlab = &quot;&quot;, type=&#39;l&#39; ) title(paste(&quot;Effect =&quot;, EFFECT, &quot;cv =&quot;, max(BCV_90perc_vec), &quot;Alpha=0.05, Beta=0.80&quot;)) } mtext(side = 1, outer = T, &quot;Gene Coverage&quot;) mtext(side = 2, outer = T, &quot;Samples Needed&quot;) mtext(side = 3, outer = T, cex = 1.25, &quot;Negative Binomial 2 Group Sample Size Curves&quot;) Figure 2.7: Sample Size Estimates Note that with these data, moderate sample sizes are adequate to detect genes with an effect size of 1.2 (20% fold change). This is due to the fact that the biological variability in gene body 5hmC density is quite low. For human samples, RNA-Seq within group biological variability is typically in the 0.4-1.0 range [10]. 2.4 Differential representation analysis word on GC content "],
["baseline-model.html", "Section 3 Baseline Model", " Section 3 Baseline Model In the section we look at the baseline model fit: What is the accuracy? Look at individual points and store some sample scores Baseline model how separable are the data individual sample quality "],
["model-suite.html", "Section 4 Fitted Model Suite", " Section 4 Fitted Model Suite We examine the results of fitting a suite of models to investigate the effect of sample size on model performance. "],
["conclusions.html", "Section 5 Conclusions", " Section 5 Conclusions We have found that … Other questions … "],
["references.html", "References", " References "]
]
