<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 3 Modeling - Background | DNA Hydroxymethylation in Hepatocellular Carcinoma</title>
  <meta name="description" content="Data from Cai et al. (2019) paper are explored" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 3 Modeling - Background | DNA Hydroxymethylation in Hepatocellular Carcinoma" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Data from Cai et al. (2019) paper are explored" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 3 Modeling - Background | DNA Hydroxymethylation in Hepatocellular Carcinoma" />
  
  <meta name="twitter:description" content="Data from Cai et al. (2019) paper are explored" />
  

<meta name="author" content="Francois Collin" />


<meta name="date" content="2020-09-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preproc.html"/>
<link rel="next" href="explore-glmnet.html"/>
<script src="libs/header-attrs-2.2/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DNA Hydroxymethylation in Hepatocellular Carcinoma</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preamble</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="preproc.html"><a href="preproc.html"><i class="fa fa-check"></i><b>2</b> Preprocessing</a>
<ul>
<li class="chapter" data-level="2.1" data-path="preproc.html"><a href="preproc.html#load-the-data"><i class="fa fa-check"></i><b>2.1</b> Load the data</a></li>
<li class="chapter" data-level="2.2" data-path="preproc.html"><a href="preproc.html#dra"><i class="fa fa-check"></i><b>2.2</b> Differential representation analysis</a>
<ul>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#remove-lowly-expressed-genes"><i class="fa fa-check"></i>Remove lowly expressed genes</a></li>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#creating-a-design-matrix-and-contrasts"><i class="fa fa-check"></i>Creating a design matrix and contrasts</a></li>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#removing-heteroscedasticity-from-the-count-data"><i class="fa fa-check"></i>Removing heteroscedasticity from the count data</a></li>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#fit-linear-models-and-examine-the-results"><i class="fa fa-check"></i>Fit linear models and examine the results</a></li>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#graphical-representations-of-differential-expression-results-md-plots"><i class="fa fa-check"></i>Graphical representations of differential expression results: MD Plots</a></li>
<li class="chapter" data-level="2.2.1" data-path="preproc.html"><a href="preproc.html#number-of-de-genes-at-10-fold-change"><i class="fa fa-check"></i><b>2.2.1</b> Number of DE genes at 10% fold change</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="preproc.html"><a href="preproc.html#analysis-of-coverage-variability"><i class="fa fa-check"></i><b>2.3</b> Analysis of coverage variability</a>
<ul>
<li class="chapter" data-level="" data-path="preproc.html"><a href="preproc.html#another-look-at-bcv"><i class="fa fa-check"></i>Another look at BCV</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modeling-background.html"><a href="modeling-background.html"><i class="fa fa-check"></i><b>3</b> Modeling - Background</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modeling-background.html"><a href="modeling-background.html#predictive-modeling-for-genomic-data"><i class="fa fa-check"></i><b>3.1</b> Predictive modeling for genomic data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="modeling-background.html"><a href="modeling-background.html#caret-for-model-evaluation"><i class="fa fa-check"></i><b>3.1.1</b> caret for model evaluation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modeling-background.html"><a href="modeling-background.html#glmnet"><i class="fa fa-check"></i><b>3.2</b> glmnet</a>
<ul>
<li><a href="modeling-background.html#alpha-hyper-parameter"><strong>alpha</strong> hyper-parameter</a></li>
<li class="chapter" data-level="" data-path="modeling-background.html"><a href="modeling-background.html#lasso-vs-best-subset"><i class="fa fa-check"></i>Lasso vs Best Subset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="explore-glmnet.html"><a href="explore-glmnet.html"><i class="fa fa-check"></i><b>4</b> Explore glmnet fits</a>
<ul>
<li class="chapter" data-level="4.1" data-path="explore-glmnet.html"><a href="explore-glmnet.html#lasso"><i class="fa fa-check"></i><b>4.1</b> lasso</a></li>
<li class="chapter" data-level="4.2" data-path="explore-glmnet.html"><a href="explore-glmnet.html#relaxed-lasso"><i class="fa fa-check"></i><b>4.2</b> Relaxed lasso</a></li>
<li class="chapter" data-level="4.3" data-path="explore-glmnet.html"><a href="explore-glmnet.html#shrunken-relaxed-lasso"><i class="fa fa-check"></i><b>4.3</b> Shrunken relaxed lasso</a></li>
<li class="chapter" data-level="4.4" data-path="explore-glmnet.html"><a href="explore-glmnet.html#ridge"><i class="fa fa-check"></i><b>4.4</b> ridge</a></li>
<li class="chapter" data-level="4.5" data-path="explore-glmnet.html"><a href="explore-glmnet.html#mid-point-between-ridge-and-lasso"><i class="fa fa-check"></i><b>4.5</b> Mid-point between ridge and lasso</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-suite.html"><a href="model-suite.html"><i class="fa fa-check"></i><b>5</b> Fitted Model Suite</a></li>
<li class="chapter" data-level="6" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>6</b> Conclusions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="LICENSE.md" style="font:em;" target="blank">Copyright (c) 2020 Francois Collin</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DNA Hydroxymethylation in Hepatocellular Carcinoma</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modeling-background" class="section level1" number="3">
<h1><span class="header-section-number">Section 3</span> Modeling - Background</h1>
<p>Refer to <a href="https://hcc-5hmc-analysis.netlify.app/">first pass study</a> for
background.</p>
<p>In the section we look at some models fitted to discriminate between
early stage HCC and control samples comprising of healthy and benign samples
from the GSE112679 data set.</p>
<ul>
<li>Baseline model
<ul>
<li>how separable are the data: what accuracy do we expect</li>
<li>individual sample quality scores: which samples are hard to classify?</li>
</ul></li>
</ul>
<div id="predictive-modeling-for-genomic-data" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Predictive modeling for genomic data</h2>
<p>The main problem in calibrating predictive models to genomic data is that
there are way more features than there are example cases to fit to. As
we have too many variables, fitting methods tend to overfit. This problem
requires that we remove variables, regularize or both. See the
Trevor Hastie talk:
<a href="https://web.stanford.edu/~hastie/TALKS/SLBD_new.pdf">Statistical Learning with Big Data - Trevor Hastie</a>.</p>
<div id="caret-for-model-evaluation" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> caret for model evaluation</h3>
<p><a href="https://topepo.github.io/caret/index.html">The <code>caret</code> Package</a>
provide a set of functions that streamline the process for fitting and
evalluating a large numbet of predictive models in parallel. The package contains tools for:</p>
<ul>
<li>data splitting<br />
</li>
<li>pre-processing<br />
</li>
<li>feature selection<br />
</li>
<li>model tuning using resampling<br />
</li>
<li>variable importance estimation</li>
</ul>
<p>The tools facilitate the process of automating randomly spliting data sets into training,
testing and evaluating so that predictive models can be evaluated on a comparable and
exhaustive basis. Especially useful is the functionality that is provided to
repeatedly randomly stratify samples into train and test set so that any
sample selection bias is removed.</p>
<p>Some of the models which can be evaluated with caret include:
(only some of these can be used with multinomial responses)</p>
<ul>
<li>FDA - Flexible Discriminant Analysis<br />
</li>
<li>stepLDA - Linear Discriminant Analysis with Stepwise Feature Selection<br />
</li>
<li>stepQDA - Quadratic Discriminant Analysis with Stepwise Feature Selection<br />
</li>
<li>knn - k nearest neighbors<br />
</li>
<li>pam - Nearest shrunken centroids<br />
</li>
<li>rf - Random forests<br />
</li>
<li>svmRadial - Support vector machines (RBF kernel)<br />
</li>
<li>gbm - Boosted trees<br />
</li>
<li>xgbLinear - eXtreme Gradient Boosting<br />
</li>
<li>xgbTree - eXtreme Gradient Boosting<br />
</li>
<li>neuralnet - neural network</li>
</ul>
<p>Many more models can be implemented and evaluated with <code>caret</code>,
including some <code>deep learning</code> methods.</p>
<p><code>Simulated Annealing Feature Selection</code> and <code>Genetic Algorithms</code>.
Many methods found <a href="https://topepo.github.io/caret/available-models.html">here</a>
are also worth investigating.</p>
</div>
</div>
<div id="glmnet" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> glmnet</h2>
<p>In this investigation we will focus on models that can be
analyzed with the the <code>glmnet</code> R package <span class="citation">[<a href="references.html#ref-Friedman:2010aa" role="doc-biblioref">26</a>]</span>. Several
factors favor this choice:</p>
<ul>
<li><p>the glmnet package is a well supported package providing
extensive functionality for regularized regression and classification models</p></li>
<li><p>the hyper-parameters of the elastic net enable us to explore
the relationship between model size, or sparsity, and predictive accuracy.
ie. we can investigate the “bet on sparsity” principle:
<em>Use a procedure that does well in sparse problems, since no procedure
does well in dense problems</em>.</p></li>
<li><p>in our experience building classifiers from genomic scale data, regularized
classification models using the elastic net penalty do as well as any other,
and are more economical in terms of computing time, espacially in comparison to
the more exotic boosting algorithms.</p></li>
<li><p>the <code>relaxed lasso</code>, introduced in version 3.0 of <code>glmnet</code>, has been shown
to be near optimal over a wide range of signal-to-noise regiments.</p></li>
</ul>
<p>One question that is of keen interest is where on the bias-variance,
or signal-to-noise (SNR) spectrum does the classification of blood samples
by means of 5hmc profiles lie?</p>
<hr />
<p>Much of the following comes from the
<a href="https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html">Glmnet Vignette</a>.</p>
<p>Glmnet is a package that fits a generalized linear model via penalized maximum likelihood.
The regularization path is computed for the lasso or elasticnet penalty at a
grid of values for the regularization parameter lambda
(<span class="citation">[<a href="references.html#ref-Friedman:2010aa" role="doc-biblioref">26</a>–<a href="references.html#ref-Simon:2013aa" role="doc-biblioref">29</a>]</span>).</p>
<p><code>glmnet</code> solves the following problem:</p>
<p><span class="math display">\[\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],\]</span></p>
<p>over a grid of values of <span class="math inline">\(\lambda\)</span>.
Here <span class="math inline">\(l(y,\eta)\)</span> is the negative log-likelihood contribution for observation i;
e.g. for the Gaussian case it is <span class="math inline">\(\frac{1}{2}(y-\eta)^2\)</span>.</p>
<div id="alpha-hyper-parameter" class="section level3 unnumbered" number="">
<h3><strong>alpha</strong> hyper-parameter</h3>
<p>The elastic-net penalty is controlled by <span class="math inline">\(\alpha\)</span>, and bridges the gap between
lasso (<span class="math inline">\(\alpha\)</span>=1, the default) and ridge (<span class="math inline">\(\alpha\)</span>=0).
The tuning parameter <span class="math inline">\(\lambda\)</span> controls the overall strength of the penalty.</p>
<p>It is known that the ridge penalty shrinks the coefficients of correlated predictors
towards each other while the lasso tends to pick one of them and discard the others.
The elastic-net penalty mixes these two; if predictors are correlated in groups,
an <span class="math inline">\(\alpha\)</span>=0.5 tends to select the groups in or out together.
This is a higher level parameter, and users might pick a value upfront,
else experiment with a few different values. One use of <span class="math inline">\(\alpha\)</span> is for numerical stability;
for example, the <em>elastic net with <span class="math inline">\(\alpha = 1 - \epsilon\)</span> for some small <span class="math inline">\(\epsilon\)</span>&gt;0
performs much like the lasso, but removes any degeneracies and wild behavior caused
by extreme correlations</em>.</p>
</div>
<div id="lasso-vs-best-subset" class="section level3 unnumbered" number="">
<h3>Lasso vs Best Subset</h3>
<ul>
<li>Best subset selection</li>
</ul>
<p><span class="math display">\[\min_{\beta \in \mathcal{R}^p} ||Y - X\beta||^2_2 \, \, subject \, to \, \, ||\beta||_0 \leq k\]</span></p>
<ul>
<li>lasso</li>
</ul>
<p><span class="math display">\[\min_{\beta \in \mathcal{R}^p} ||Y - X\beta||^2_2 \, \, subject \, to \, \, ||\beta||_1 \leq t\]</span></p>
<ul>
<li>Bertsimas et al. (2016) <span class="citation">[<a href="references.html#ref-Bertsimas:2016aa" role="doc-biblioref">30</a>]</span>
<ul>
<li>presented a mixed integer optimization (MIO) formulation for the best subset selection problem<br />
</li>
<li>Using these MIO solvers, can solve problems with p in the hundreds and even thousands</li>
<li>demonstrated that best subset selection generally gives superior prediction accuracy compared to forward stepwise selection and the lasso, over a variety of problem setups.</li>
</ul></li>
<li>Hastie et al. (2017) <span class="citation">[<a href="references.html#ref-Hastie:2017aa" role="doc-biblioref">31</a>]</span>
<ul>
<li>neither best subset selection nor the lasso uniformly dominate the other, with best subset selection generally performing better in high signal-to-noise (SNR) ratio regimes, and the lasso better in low SNR regimes;</li>
<li>best subset selection and forward stepwise perform quite similarly throughout;</li>
<li>the relaxed lasso is the overall winner, performing just about as well as the lasso in low SNR scenarios,
and as well as best subset selection in high SNR scenarios. We conclude that it is
able to use its auxiliary shrinkage parameter (γ) to get the “best of both worlds”:
it accepts the heavy shrinkage from the lasso when such shrinkage is helpful, and reverses it when it is not.</li>
</ul></li>
<li>relaxed lasso</li>
</ul>
<p><span class="math display">\[\hat{\beta}^{relax}(\lambda, \gamma) = \gamma \beta^{lasso}(\lambda) + (1 - \gamma)(\beta^{LS}(\lambda)\]</span></p>
<ul>
<li>shrunken relaxed lasso</li>
</ul>
<p>Suppose the <strong>glmnet</strong> fitted linear predictor at <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(\hat{\eta}_\lambda(x)\)</span>
and the relaxed version is <span class="math inline">\(\tilde{\eta}_\lambda(x)\)</span>, then the shrunken relaxed lasso fit is</p>
<p><span class="math display">\[\tilde{\eta}_{\lambda,\gamma}(x)=(1-\gamma)\tilde{\eta}_\lambda(x) + \gamma \hat{\eta}_\lambda(x)\]</span></p>
<p><span class="math inline">\(\gamma \in [0,\, 1]\)</span> is an additional tuning parameter which can be selected by cross validation.</p>
<p>The debiasing will potentially improve prediction performance, and CV will typically select a model
with a smaller number of variables. This procedure is very competitive with forward-stepwise and
best-subset regression, and has a considerable speed advantage when the number of variables is large.
This is especially true for best-subset, but even so for forward stepwise.
The latter has to plod through the variables one-at-a-time,
while glmnet will just plunge in and find a good active set.</p>
<p>Further details may be found in
Friedman, Hastie, and Tibshirani (2010),
Tibshirani et al. (2012),
Simon et al. (2011),
Simon, Friedman, and Hastie (2013) and
Hastie, Tibshirani, and Tibshirani (2017)
(<span class="citation">[<a href="references.html#ref-Friedman:2010aa" role="doc-biblioref">26</a>–<a href="references.html#ref-Simon:2013aa" role="doc-biblioref">29</a>,<a href="references.html#ref-Hastie:2017aa" role="doc-biblioref">31</a>]</span>).</p>
<ul>
<li>SNR
<ul>
<li><span class="math inline">\(y_0=f(x_0) + \epsilon_0\)</span></li>
<li><span class="math inline">\(SNR=\frac{var(f(x_0))}{var(\epsilon_0)}\)</span></li>
<li><span class="math inline">\(PVE(g)=1 - \frac{\mathbb{E}(y_0-g(x_0))^2}{Var(y_0)}\)</span></li>
<li><span class="math inline">\(PVE(f) = 1 - \frac{Var(\epsilon_0)}{Var(y_0)} = \frac{SNR}{1+SNR}\)</span></li>
<li><span class="math inline">\(SNR = \frac{PVE}{1-PVE}\)</span></li>
<li><span class="math inline">\(c_v = \frac{\sigma}{\mu}=\frac{Var(y)}{\mathbb{E}(y)}\)</span>
<ul>
<li>a PVE of 0.5 is rare for noisy observational data, and 0.2 may be more typical</li>
<li>A PVE of 0.86, corresponding to an SNR of 6, is unheard of!</li>
<li>For small SNR, SNR <span class="math inline">\(\approx\)</span> PVE</li>
<li>See Xiang et al. (2020) <span class="citation">[<a href="references.html#ref-Xiang:2020aa" role="doc-biblioref">32</a>]</span>, Lozoya et al. (2018) <span class="citation">[<a href="references.html#ref-Lozoya:2018aa" role="doc-biblioref">33</a>]</span>,
Simonson et al. (2018) <span class="citation">[<a href="references.html#ref-Simonsen:2018aa" role="doc-biblioref">34</a>]</span> and
Rapaport et al. (2013) <span class="citation">[<a href="references.html#ref-Rapaport:2013aa" role="doc-biblioref">35</a>]</span> for SNR in RNA-Seq</li>
</ul></li>
</ul></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="preproc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="explore-glmnet.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["HCC5hmCExplore.pdf", "HCC5hmCExplore.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
